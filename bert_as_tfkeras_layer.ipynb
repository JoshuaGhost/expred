{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "hsZvic2YxnTz",
    "outputId": "35722f7e-f064-4fb8-ecf7-c9de0b745a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/zzhang/workspace/interpretation_by_design/.venv/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from utils import *\n",
    "from display_rational import convert_res_to_htmls\n",
    "from config import *\n",
    "from losses import imbalanced_bce_bayesian, imbalanced_bce_resampling, exp_interval_loss\n",
    "from metrices import *\n",
    "from tqdm import tqdm_notebook\n",
    "from bert import optimization\n",
    "from bert import run_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import bert\n",
    "\n",
    "import tensorflow\n",
    "if tensorflow.__version__.startswith('2'):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "else:\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss of the multi-task learning is:\n",
    "$$\n",
    "\\mathcal{L}_{total} = \\mathcal{L}_{cls} + \\lambda\\mathcal{L}_{exp}\\text{,}\n",
    "$$\n",
    "where $\\mathcal{L}_{cls}$ is the loss of the classification task, $\\mathcal{L}_{exp}$ is the token-wise average of explaination loss (averaged cross entropy) and $S$ indicates the length of the input text. The hyper-parameter $\\lambda$ is written as ```par_lambda``` in the following cells since 'lambda' is a reserved word in python.\n",
    "\n",
    "The loss function has been changed since 2020.01.08. The old formulation of the loss function tried to balance between cls loss and exp loss, which down-scale both term as well as their learning rate. The new schema respect the global learning rate w.r.t. cls part while one can modify the learning rate of explaination part through $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# variable hyper-parameters\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--par_lambda', type=float)\n",
    "parser.add_argument('--gpu_id', type=str)\n",
    "parser.add_argument('--batch_size', type=int)\n",
    "parser.add_argument('--num_epochs', type=int)\n",
    "parser.add_argument('--dataset', type=str, choices='fever multirc movies'.split())\n",
    "parser.add_argument(\"--do_train\", action='store_true')\n",
    "parser.add_argument('--exp_visualize', action='store_true')\n",
    "parser.add_argument('--evaluate', action='store_true')\n",
    "parser.add_argument('--exp_benchmark', action='store_true')\n",
    "parser.add_argument('--modeling_structure', type=str, default='bert', choices='bert lstm'.split())\n",
    "parser.add_argument('--exp_structure', type=str, default='gru', choices='gru rnr'.split())\n",
    "parser.add_argument('--delete_checkpoints', action='store_true')\n",
    "parser.add_argument('--merge_evidences', action='store_true')\n",
    "\n",
    "args = ['--par_lambda', '0.01', \n",
    "        '--gpu_id', '-1', \n",
    "        '--batch_size', '2', \n",
    "        '--num_epochs', '10',\n",
    "        '--dataset', 'movies',\n",
    "        '--do_train',\n",
    "        '--evaluate',\n",
    "        '--exp_benchmark',\n",
    "        '--modeling_structure', 'lstm',\n",
    "        '--exp_structure', 'rnr',\n",
    "        '--delete_checkpoints',\n",
    "        '--merge_evidences']\n",
    "\n",
    "args = parser.parse_args(args)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "BATCH_SIZE = args.batch_size\n",
    "par_lambda = args.par_lambda\n",
    "NUM_EPOCHS = args.num_epochs\n",
    "gpu_id = args.gpu_id\n",
    "exp_structure = args.exp_structure\n",
    "dataset = args.dataset\n",
    "DO_DELETE = args.delete_checkpoints\n",
    "do_train = args.do_train\n",
    "load_best = not do_train\n",
    "evaluate = args.evaluate\n",
    "exp_visualize = args.exp_visualize\n",
    "exp_benchmark = args.exp_benchmark\n",
    "merge_evidences = args.merge_evidences\n",
    "\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# static hyper-parameters\n",
    "MAX_SEQ_LENGTH = 512\n",
    "HARD_SELECTION_COUNT = None\n",
    "HARD_SELECTION_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "US_EAnICvP7f"
   },
   "outputs": [],
   "source": [
    "# Set the output directory for saving model file\n",
    "# Optionally, set a GCP bucket location\n",
    "from losses import rnr_matrix_loss\n",
    "\n",
    "\n",
    "bert_size = 'base'\n",
    "#bert_size = 'large'\n",
    "\n",
    "if bert_size == 'base':\n",
    "    BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "#pooling = 'mean'\n",
    "pooling = 'first'\n",
    "\n",
    "EXP_OUTPUT = exp_structure\n",
    "\n",
    "rebalance_approach = 'resampling'\n",
    "#rebalance_approach = 'bayesian'\n",
    "if EXP_OUTPUT == 'gru':\n",
    "    if rebalance_approach == 'resampling':\n",
    "        loss_function = imbalanced_bce_resampling\n",
    "    else:\n",
    "        loss_function = imbalanced_bce_bayesian\n",
    "elif EXP_OUTPUT == 'rnr':\n",
    "    loss_function = rnr_matrix_loss\n",
    "    \n",
    "suffix = ''\n",
    "#suffix = 'cls_only'\n",
    "#suffix = 'transfer_cls_to_exp'\n",
    "#suffix = 'transfer_exp_to_cls'\n",
    "\n",
    "OUTPUT_DIR = ['bert_{}_seqlen_{}_{}_exp_output_{}'.format(\n",
    "    bert_size, MAX_SEQ_LENGTH, dataset, EXP_OUTPUT)]\n",
    "OUTPUT_DIR.append('merged_evidences' if merge_evidences else 'separated_evidences')\n",
    "DATASET_CACHE_NAME = '_'.join(OUTPUT_DIR) + '_inputdata_cache'\n",
    "if par_lambda is None:\n",
    "    OUTPUT_DIR.append('no_weight')\n",
    "else:\n",
    "    OUTPUT_DIR.append('par_lambda_{}'.format(par_lambda))\n",
    "OUTPUT_DIR.append('no_padding_imbalanced_bce_{}_pooling_{}_learning_rate_{}'.format(rebalance_approach, pooling, LEARNING_RATE))\n",
    "OUTPUT_DIR.append(suffix)\n",
    "OUTPUT_DIR = '_'.join(OUTPUT_DIR)\n",
    "MODEL_NAME = OUTPUT_DIR\n",
    "OUTPUT_DIR = os.path.join('model_checkpoints', MODEL_NAME)\n",
    "\n",
    "# @markdown Whether or not to clear/delete the directory and create a new one\n",
    "#DO_DELETE = False  # @param {type:\"boolean\"}\n",
    "# @markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
    "USE_BUCKET = False  # @param {type:\"boolean\"}\n",
    "BUCKET = 'bert-base-uncased-test0'  # @param {type:\"string\"}\n",
    "\n",
    "if USE_BUCKET:\n",
    "    OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "if DO_DELETE:\n",
    "    try:\n",
    "        tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "    except:\n",
    "        # Doesn't matter if the directory didn't exist\n",
    "        pass\n",
    "if tensorflow.__version__.startswith('2'):\n",
    "    tf.io.gfile.makedirs(OUTPUT_DIR)\n",
    "else:\n",
    "    tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# data loading and preprocessing\n",
    "'''\n",
    "if dataset == 'semeval18':\n",
    "    from load_data_semeval18 import download_and_load_datasets\n",
    "    DATA_COLUMNS = 'Tweet text'\n",
    "    LABEL_COLUMN = 'Label'\n",
    "elif dataset == 'eraser_multirc':\n",
    "    from load_data_eraser_multirc import download_and_load_datasets\n",
    "    DATA_COLUMNS = ['query', 'passage']\n",
    "    LABEL_COLUMN = 'classification'\n",
    "elif dataset == 'eraser_fever':\n",
    "    from load_data_eraser_fever import download_and_load_datasets\n",
    "    DATA_COLUMNS = ['query', 'passage']\n",
    "    LABEL_COLUMN = 'classification'\n",
    "else:\n",
    "    if dataset == 'acl_imdb' or dataset == 'acl_imdb_cls':\n",
    "        from load_data_acl_imdb import download_and_load_datasets\n",
    "    if dataset == 'semeval16' or dataset == 'semeval16_cls':\n",
    "        from load_data_semeval16 import download_and_load_datasets\n",
    "    if dataset == 'zaidan07_cls':\n",
    "        from load_data_imdb_zaidan07_cls import download_and_load_datasets\n",
    "    if dataset == 'zaidan07_seq' or dataset == 'zaidan07_mtl':\n",
    "        from load_data_imdb_zaidan07_seq import download_and_load_datasets\n",
    "    if dataset == 'eraser_movie_mtl':\n",
    "        from load_data_imdb_zaidan07_eraser import download_and_load_datasets\n",
    "    DATA_COLUMNS = ['sentence']\n",
    "    LABEL_COLUMN = 'polarity'\n",
    "\n",
    "ret = download_and_load_datasets()\n",
    "if len(ret) == 3:\n",
    "    train, val, test = ret\n",
    "else:\n",
    "    train, test = ret\n",
    "    val = train.sample(frac=0.2)\n",
    "    train = pd.merge(train, val, how='outer', indicator=True)\n",
    "    train = train.loc[train._merge == 'left_only', ['sentence', 'polarity']]\n",
    "label_list = [0, 1]\n",
    "\n",
    "# data preprocessing\n",
    "from bert_data_preprocessing_rational import load_bert_features, convert_bert_features\n",
    "\n",
    "\n",
    "def preprocess(data, label_list, dataset_name):\n",
    "    features = load_bert_features(\n",
    "        data, label_list, MAX_SEQ_LENGTH, DATA_COLUMNS, LABEL_COLUMN)\n",
    "\n",
    "    with_rations = ('cls' not in dataset_name)\n",
    "    with_lable_id = ('seq' not in dataset_name)\n",
    "\n",
    "    return convert_bert_features(features, with_lable_id, with_rations, EXP_OUTPUT)\n",
    "\n",
    "\n",
    "@cache_decorator(os.path.join('cache', DATASET_NAME))\n",
    "def preprocess_wrapper(*data_inputs):\n",
    "    ret = []\n",
    "    for data in data_inputs:\n",
    "        ret.append(preprocess(data, label_list, dataset))\n",
    "    return ret\n",
    "\n",
    "\n",
    "rets_train, rets_val, rets_test = preprocess_wrapper(train, val, test)\n",
    "\n",
    "train_input_ids, train_input_masks, train_segment_ids, train_rations, train_labels = rets_train\n",
    "val_input_ids, val_input_masks, val_segment_ids, val_rations, val_labels = rets_val\n",
    "test_input_ids, test_input_masks, test_segment_ids, test_rations, test_labels = rets_test\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# initializing graph and session\n",
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = gpu_id\n",
    "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# data loading and preprocessing from eraser\n",
    "from eraserbenchmark.rationale_benchmark.utils import load_datasets, load_documents\n",
    "from eraserbenchmark.eraser_utils import extract_doc_ids_from_annotations\n",
    "from itertools import chain\n",
    "\n",
    "if dataset == 'movies':\n",
    "    label_list = ['POS', 'NEG']\n",
    "elif dataset == 'multirc':\n",
    "    label_list = ['True', 'False']\n",
    "elif dataset == 'fever':\n",
    "    label_list = ['SUPPORTS', 'REFUTES']\n",
    "\n",
    "data_dir = f'/home/zzhang/.keras/datasets/{dataset}/'\n",
    "train, val, test = load_datasets(data_dir)\n",
    "#train, val, test = [expand_on_evidences(data) for data in [train, val, test]]\n",
    "docids = set(chain.from_iterable(extract_doc_ids_from_annotations(d) for d in [train, val, test]))\n",
    "docs = load_documents(data_dir, docids)\n",
    "\n",
    "from bert_data_preprocessing_rational_eraser import preprocess\n",
    "@cache_decorator(os.path.join('cache', DATASET_CACHE_NAME + '_eraser_format'))\n",
    "def preprocess_wrapper(*data_inputs, docs=docs):\n",
    "    ret = []\n",
    "    for data in data_inputs:\n",
    "        ret.append(preprocess(data, docs, label_list, dataset, MAX_SEQ_LENGTH, EXP_OUTPUT, merge_evidences))\n",
    "    return ret\n",
    "\n",
    "rets_train, rets_val, rets_test = preprocess_wrapper(train, val, test, docs=docs)\n",
    "\n",
    "train_input_ids, train_input_masks, train_segment_ids, train_rations, train_labels = rets_train\n",
    "val_input_ids, val_input_masks, val_segment_ids, val_rations, val_labels = rets_val\n",
    "test_input_ids, test_input_masks, test_segment_ids, test_rations, test_labels = rets_test\n",
    "\n",
    "def expand_on_evidences(data):\n",
    "    from copy import deepcopy\n",
    "    from eraserbenchmark.rationale_benchmark.utils import Annotation\n",
    "    expanded_data = []\n",
    "    for ann in tqdm_notebook(data):\n",
    "        for ev_group in ann.evidences:\n",
    "            new_ann = Annotation(annotation_id=ann.annotation_id,\n",
    "                                 query=ann.query,\n",
    "                                 evidences=frozenset([ev_group]),\n",
    "                                 classification=ann.classification)\n",
    "            expanded_data.append(new_ann)\n",
    "    return expanded_data\n",
    "#expanded_test = expand_on_evidences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# hyper-parameters of BERT's\n",
    "WARMUP_PROPORTION = 0.1\n",
    "\n",
    "num_train_steps = int(len(train_input_ids) / BATCH_SIZE * float(NUM_EPOCHS))\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bert_utils import get_vocab\n",
    "vocab = get_vocab(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# building models\n",
    "from model import BertLayer\n",
    "from tensorflow.keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Multiply, Concatenate, RepeatVector, Dot, Lambda, Add\n",
    "\n",
    "from metrices import sp_precision_wrapper, sp_recall_wrapper\n",
    "\n",
    "DIM_DENSE_CLS = 256\n",
    "NUM_GRU_UNITS_BERT_SEQ = 128\n",
    "NUM_INTERVAL_LSTM_WIDTH = 100\n",
    "\n",
    "\n",
    "def build_model(par_lambda=None):\n",
    "    in_id = Input(shape=(MAX_SEQ_LENGTH,), name=\"input_ids\")\n",
    "    in_mask = Input(shape=(MAX_SEQ_LENGTH,), name=\"input_masks\")\n",
    "    in_segment = Input(shape=(MAX_SEQ_LENGTH,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    bert_cls_output, bert_exp_output = BertLayer(\n",
    "        n_fine_tune_layers=10)(bert_inputs)\n",
    "\n",
    "    outputs = []\n",
    "    if 'seq' not in dataset:\n",
    "        # Classifier output\n",
    "        dense = Dense(DIM_DENSE_CLS, activation='tanh')(bert_cls_output)\n",
    "        cls = Dense(1, activation='sigmoid', name='cls_output')(dense)\n",
    "        outputs.append(cls)\n",
    "    if 'cls' not in dataset:\n",
    "        # Explainer output\n",
    "        if EXP_OUTPUT == 'gru':\n",
    "            gru = CuDNNGRU(\n",
    "                NUM_GRU_UNITS_BERT_SEQ, kernel_initializer='random_uniform', return_sequences=True)(bert_exp_output)\n",
    "            exp = Dense(1, activation='sigmoid')(gru)\n",
    "            output_mask = Reshape((512, 1))(in_mask)\n",
    "            exp_outputs = Multiply(name='exp_output')([output_mask, exp])\n",
    "        elif EXP_OUTPUT == 'rnr':\n",
    "            M1 = Bidirectional(layer=CuDNNLSTM(NUM_INTERVAL_LSTM_WIDTH, return_sequences=True),\n",
    "                               merge_mode='concat')(bert_exp_output)\n",
    "            p_starts = Dense(1, activation='sigmoid')(Concatenate(axis=-1)([bert_exp_output, M1]))\n",
    "\n",
    "            m1_tilde = Dot(axes=-2)([p_starts, M1])\n",
    "            M1_tilde = Lambda(lambda x: tf.tile(x, (1, MAX_SEQ_LENGTH, 1)))(m1_tilde)\n",
    "            x = Multiply()([M1, M1_tilde])\n",
    "            M2 = Bidirectional(layer=CuDNNLSTM(NUM_INTERVAL_LSTM_WIDTH, return_sequences=True),\n",
    "                               merge_mode='concat')(Concatenate(axis=-1)([bert_exp_output, M1, M1_tilde, x]))\n",
    "            p_end_given_start = Dense(MAX_SEQ_LENGTH, activation='softmax')(Concatenate(axis=-1)([bert_exp_output, M2]))\n",
    "            p_end_given_start = Lambda(lambda x: tf.linalg.band_part(x, 0, -1))(p_end_given_start)\n",
    "            exp_outputs = Concatenate(axis=-1, name='exp_output')([p_starts, p_end_given_start])\n",
    "            #exp_outputs = Lambda(lambda x: tf.reduce_sum(x, axis=-1, keepdims=True), name='exp_output')(p_dist)\n",
    "        outputs.append(exp_outputs)\n",
    "\n",
    "    model = Model(inputs=bert_inputs, outputs=outputs)\n",
    "    optimizer = Adam(LEARNING_RATE)\n",
    "    \n",
    "    if par_lambda is None:\n",
    "        loss_weights = None\n",
    "    else:\n",
    "        loss_weights = {'cls_output': 1,\n",
    "                        'exp_output': par_lambda}\n",
    "    metrics = {'cls_output': 'accuracy',\n",
    "               'exp_output': [f1_wrapper(EXP_OUTPUT),\n",
    "                              sp_precision_wrapper(EXP_OUTPUT),\n",
    "                              sp_recall_wrapper(EXP_OUTPUT),\n",
    "                              precision_wrapper(EXP_OUTPUT),\n",
    "                              recall_wrapper(EXP_OUTPUT)]}\n",
    "    loss = {'cls_output': 'binary_crossentropy',\n",
    "            'exp_output': loss_function()}\n",
    "    '''\n",
    "    metrics = [f1_wrapper(EXP_OUTPUT),\n",
    "                              sp_precision_wrapper(EXP_OUTPUT),\n",
    "                              sp_recall_wrapper(EXP_OUTPUT),\n",
    "                              precision_wrapper(EXP_OUTPUT),\n",
    "                              recall_wrapper(EXP_OUTPUT)]\n",
    "    loss = loss_function()\n",
    "    '''\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    model_exp = Model(inputs=bert_inputs, outputs=exp_outputs)\n",
    "    optimizer = Adam(LEARNING_RATE)\n",
    "    model_exp.compile(loss=loss_function(), optimizer=optimizer)\n",
    "\n",
    "    return model, model_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "code_folding": [
     84,
     93
    ],
    "colab": {},
    "colab_type": "code",
    "id": "nucD4gluYJmK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training, evaluation and inference\n",
    "import os\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "checkpoint_path = os.path.join(OUTPUT_DIR, 'cp-{epoch:04d}.ckpt')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cls_output_file = os.path.join(OUTPUT_DIR, 'output.txt')\n",
    "\n",
    "BENCHMARK_SPLIT_NAME = 'test'\n",
    "RES_FOR_BENCHMARK_FNAME = MODEL_NAME + '_' + BENCHMARK_SPLIT_NAME\n",
    "\n",
    "with graph.as_default():\n",
    "    set_session(sess)\n",
    "    model, model_exp = build_model(par_lambda)\n",
    "    model.summary()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    training_inputs = [train_input_ids, train_input_masks, train_segment_ids]\n",
    "    # training_inputs = [train_input_ids[:10],\n",
    "    #                   train_input_masks[:10], train_segment_ids[:10]]\n",
    "    val_inputs = [val_input_ids, val_input_masks, val_segment_ids]\n",
    "    test_inputs = [test_input_ids, test_input_masks, test_segment_ids]\n",
    "\n",
    "    training_outputs, test_outputs, val_outputs = {}, {}, {}\n",
    "\n",
    "    if 'seq' not in dataset:\n",
    "        training_outputs['cls_output'] = train_labels\n",
    "        #training_outputs['cls_output'] = train_labels[:10]\n",
    "        test_outputs['cls_output'] = test_labels\n",
    "        val_outputs['cls_output'] = val_labels\n",
    "    if 'cls' not in dataset:\n",
    "        training_outputs['exp_output'] = train_rations\n",
    "        #training_outputs['exp_output'] = train_rations[:10]\n",
    "        test_outputs['exp_output'] = test_rations\n",
    "        val_outputs['exp_output'] = val_rations\n",
    "\n",
    "    initial_epoch = 0\n",
    "    if load_best:\n",
    "        if dataset == 'fever':\n",
    "            best_epoch = 3\n",
    "        else:\n",
    "            with open(cls_output_file, 'r') as fin:\n",
    "                log = fin.readlines()\n",
    "            history = eval(log[2])\n",
    "            best_epoch = np.argmin(history['loss'])+1\n",
    "        model.load_weights(checkpoint_path.format(epoch=best_epoch))\n",
    "    else:\n",
    "        for ckpt_i in range(NUM_EPOCHS, 0, -1):\n",
    "            if os.path.isfile(checkpoint_path.format(epoch=ckpt_i)):\n",
    "                initial_epoch = ckpt_i\n",
    "                model.load_weights(checkpoint_path.format(epoch=ckpt_i))\n",
    "                # assert False  # dumm proof, most of the case the training is end-to-end, without disturbance and reloading\n",
    "                break\n",
    "\n",
    "    if do_train:\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=False,\n",
    "                                                         verbose=1,\n",
    "                                                         period=1)\n",
    "        es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "        with open(cls_output_file, 'a+') as fw:\n",
    "            fw.write(\"=============== {} ===============\\n\".format(datetime.now()))\n",
    "\n",
    "        history = model.fit(\n",
    "            training_inputs,\n",
    "            training_outputs,\n",
    "\n",
    "            validation_data=(val_inputs,\n",
    "                             val_outputs),\n",
    "            epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[cp_callback, es_callback],\n",
    "            initial_epoch=initial_epoch\n",
    "        )\n",
    "\n",
    "        with open(cls_output_file, 'a+') as fw:\n",
    "            fw.write(\"{}:\\n\".format(datetime.now()))\n",
    "            fw.write(str(history.history) + '\\n')\n",
    "\n",
    "    if evaluate:\n",
    "        evaluation_res = model.evaluate(x=test_inputs,\n",
    "                                        y=test_outputs,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        verbose=1)\n",
    "        with open(cls_output_file, 'a+') as fw:\n",
    "            fw.write(\"{}:\\n\".format(datetime.now()))\n",
    "            fw.write(str(evaluation_res) + '\\n')\n",
    "\n",
    "    if exp_visualize:\n",
    "        len_head = 100\n",
    "        test_inputs_head = [x[:len_head] for x in test_inputs]\n",
    "        pred = model_exp.predict(test_inputs_head)\n",
    "        pred = np.round(np.array(pred)).astype(np.int32)\n",
    "        exp_output_folder = os.path.join(OUTPUT_DIR, 'exp_outputs/')\n",
    "        tf.gfile.MakeDirs(exp_output_folder)\n",
    "        print('marked rationals are saved under {}'.format(exp_output_folder))\n",
    "        vocab = get_vocab(BERT_MODEL_HUB)\n",
    "        for i, l in enumerate(tqdm_notebook(test.iterrows())):\n",
    "            if i == len_head:\n",
    "                break\n",
    "            input_ids = test_input_ids[i]\n",
    "            pred_intp = pred[i].reshape([-1])\n",
    "            label = test_labels[i]\n",
    "            gt = test_rations[i].reshape([-1])\n",
    "            html = convert_res_to_htmls(input_ids, pred_intp, gt, vocab)\n",
    "            with open(exp_output_folder + str(l[0]) + '.html', \"w+\") as f:\n",
    "                f.write(\n",
    "                    '<h1>label: {}</h1>\\n'.format('pos' if label == 1 else 'neg'))\n",
    "                f.write(html[1] + '<br/><br/>\\n' + html[0])\n",
    "\n",
    "    if exp_benchmark:\n",
    "        from eraser_benchmark import pred_to_results\n",
    "        result_fname = RES_FOR_BENCHMARK_FNAME + '.jsonl'\n",
    "        result_fname = os.path.join(\n",
    "            'eraserbenchmark', 'annotated_by_exp', result_fname)\n",
    "\n",
    "        if BENCHMARK_SPLIT_NAME == 'test':\n",
    "            benchmark_inputs, raw_input, benchmark_input_ids = test_inputs, test, test_input_ids\n",
    "        elif BENCHMARK_SPLIT_NAME == 'val':\n",
    "            benchmark_inputs, raw_input, benchmark_input_ids = val_inputs, val, val_input_ids\n",
    "        elif BENCHMARK_SPLIT_NAME == 'train':\n",
    "            benchmark_inputs, raw_input, benchmark_input_ids = training_inputs, train, train_input_ids\n",
    "\n",
    "        pred = model.predict(x=benchmark_inputs)\n",
    "\n",
    "        # results = [pred_to_results(raw_input.loc[i], benchmark_input_ids[i], (pred[0][i], pred[1][i]), HARD_SELECTION_COUNT, HARD_SELECTION_THRESHOLD)\n",
    "        #           for i in range(len(raw_input))]\n",
    "        from eraser_benchmark import pred_to_results, get_cls_score, add_cls_scores, remove_rations, extract_rations\n",
    "        results = [pred_to_results(raw_input[i], benchmark_input_ids[i], \n",
    "                                   (pred[0][i], pred[1][i]), \n",
    "                                   HARD_SELECTION_COUNT, \n",
    "                                   HARD_SELECTION_THRESHOLD,\n",
    "                                   vocab, docs, label_list, EXP_OUTPUT)\n",
    "                   for i in range(len(pred[0]))]\n",
    "        pred_softmax = np.hstack([1-pred[0], pred[0]])\n",
    "        c_pred_softmax = get_cls_score(\n",
    "            model, results, docs, label_list, dataset, remove_rations, MAX_SEQ_LENGTH, EXP_OUTPUT)\n",
    "        s_pred_softmax = get_cls_score(\n",
    "            model, results, docs, label_list, dataset, extract_rations, MAX_SEQ_LENGTH, EXP_OUTPUT)\n",
    "\n",
    "        results = [add_cls_scores(res, cls_score, c_cls_score, s_cls_score, label_list) for res, cls_score,\n",
    "                   c_cls_score, s_cls_score in zip(results, pred_softmax, c_pred_softmax, s_pred_softmax)]\n",
    "        anns_saved = set()\n",
    "        real_results = []\n",
    "        for ann in results:\n",
    "            if ann['annotation_id'] not in anns_saved:\n",
    "                anns_saved.add(ann['annotation_id'])\n",
    "                real_results.append(ann)\n",
    "        with open(result_fname+'pkl3', \"wb+\") as pfout:\n",
    "            pickle.dump(real_results, pfout)\n",
    "        from eraserbenchmark.eraser import evaluate\n",
    "        evaluate(MODEL_NAME, dataset)\n",
    "\n",
    "    with open(cls_output_file, 'a+') as fw:\n",
    "        fw.write('/////////////////experiment ends//////////////////\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“Predicting Movie Reviews with BERT on TF Hub.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "493.667px",
    "left": "900px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
